{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "with open(\"X.txt\", \"rb\") as fp:   # Unpickling\n",
    "    X = pickle.load(fp)\n",
    "\n",
    "with open(\"Y.txt\", \"rb\") as fp:   # Unpickling\n",
    "    Y = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = model_selection.train_test_split(np.array(X),np.array(Y),test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.83      0.82       233\n",
      "          2       0.70      0.81      0.75       253\n",
      "          3       0.72      0.05      0.10       249\n",
      "          4       0.50      0.88      0.63       240\n",
      "          5       0.76      0.87      0.81       236\n",
      "          6       0.83      0.75      0.79       240\n",
      "          7       0.83      0.90      0.86       261\n",
      "          8       0.88      0.89      0.89       269\n",
      "          9       0.90      0.97      0.93       284\n",
      "         10       0.95      0.93      0.94       248\n",
      "         11       0.94      0.98      0.96       231\n",
      "         12       0.97      0.96      0.96       233\n",
      "         13       0.86      0.86      0.86       244\n",
      "         14       0.95      0.86      0.90       256\n",
      "         15       0.96      0.93      0.94       246\n",
      "         16       0.96      1.00      0.98       252\n",
      "         17       0.82      0.91      0.86       249\n",
      "         18       0.93      0.87      0.90       281\n",
      "         19       0.78      0.71      0.74       259\n",
      "         20       0.71      0.61      0.66       236\n",
      "\n",
      "avg / total       0.84      0.83      0.82      5000\n",
      "\n",
      "[[193   0   0   0   0   0   0   2   2   0   1   0   1   2   0   1   0   0\n",
      "    0  31]\n",
      " [  0 206   1  18   8  11   2   2   0   1   0   0   2   2   0   0   0   0\n",
      "    0   0]\n",
      " [  0  44  13 143  14  25   4   0   0   0   0   1   4   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   1   1 211  18   0   5   0   0   0   0   0   4   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   0  20 206   0   7   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  27   1  14   6 180   3   0   2   1   0   1   2   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   6   5   0 235   5   2   0   1   0   6   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   2   0   9 240   9   1   1   0   7   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2   6 276   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   4   2   1 231   8   0   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   3 226   0   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   5   1   0   0   1   1   0   0   0   0 224   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   0   8   5   0   6   8   1   0   1   2 209   1   1   0   0   0\n",
      "    0   0]\n",
      " [  0   6   0   1   4   0   2   4   9   2   1   0   4 219   3   0   0   1\n",
      "    0   0]\n",
      " [  0   2   0   1   1   1   1   2   2   1   2   0   1   3 228   0   0   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 252   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   0   0   1   0   0   2   0   0   0   0 227   0\n",
      "   12   6]\n",
      " [  0   0   0   2   2   0   2   2   1   1   0   0   1   0   0   0   5 245\n",
      "   17   3]\n",
      " [  0   0   0   0   0   0   1   0   0   1   0   2   0   2   1   1  33  15\n",
      "  184  19]\n",
      " [ 46   0   0   0   0   0   0   0   0   0   0   0   0   1   0   9  12   2\n",
      "   22 144]]\n"
     ]
    }
   ],
   "source": [
    "#using sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred=clf.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train, Y_train):\n",
    "    result = {}\n",
    "\n",
    "    print(\"Y train is\",Y_train)\n",
    "    class_values = set(Y_train)\n",
    "    for current_class in class_values:\n",
    "        result[current_class] = {}\n",
    "        \n",
    "        result[\"total_data\"] = len(Y_train)\n",
    "        current_class_rows = (Y_train == current_class)\n",
    "        X_train_current = X_train[current_class_rows]\n",
    "        Y_train_current = Y_train[current_class_rows]\n",
    "        num_features = len(X_train[0])\n",
    "        result[current_class][\"total_count\"] = len(Y_train_current)\n",
    "        for j in range(1, num_features + 1):\n",
    "            result[current_class][j] = {}\n",
    "            all_possible_values = set(X_train[:, j - 1])\n",
    "            for current_value in all_possible_values:\n",
    "                result[current_class][j][current_value] = (X_train_current[:, j - 1] == current_value).sum()\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(dictionary, x, current_class):\n",
    "    output = np.log(dictionary[current_class][\"total_count\"]) - np.log(dictionary[\"total_data\"])\n",
    "    num_features = len(dictionary[current_class].keys()) - 1;\n",
    "    for j in range(1, num_features + 1):\n",
    "        xj = x[j - 1]\n",
    "        count_current_class_with_value_xj=1\n",
    "        if  xj in dictionary[current_class][j]:\n",
    "            count_current_class_with_value_xj = dictionary[current_class][j][xj] + 1\n",
    "        count_current_class = dictionary[current_class][\"total_count\"] + len(dictionary[current_class][j].keys())\n",
    "        current_xj_probablity = np.log(count_current_class_with_value_xj) - np.log(count_current_class)\n",
    "        output = output + current_xj_probablity\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSinglePoint(dictionary, x):\n",
    "    classes = dictionary.keys()\n",
    "    best_p = -1000\n",
    "    best_class = -1\n",
    "    first_run = True\n",
    "    for current_class in classes:\n",
    "        if (current_class == \"total_data\"):\n",
    "            continue\n",
    "        p_current_class = probability(dictionary, x, current_class)\n",
    "        if (first_run or p_current_class > best_p):\n",
    "            best_p = p_current_class\n",
    "            best_class = current_class\n",
    "        first_run = False\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dictionary, X_test):\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        x_class = predictSinglePoint(dictionary, x)\n",
    "        y_pred.append(x_class)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y train is [19 20 13 ... 10 11  3]\n"
     ]
    }
   ],
   "source": [
    "#dictionary2 is for my naive classifier,which is multi-level\n",
    "dictionary2 = fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is taking too long so if you want to load it from the 'Y_pred_my_clf.npz' file, then comment below line\n",
    "Y_pred = predict(dictionary2,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# I have already saved Y_pred in 'Y_pred_my_clf.npz' it can be used to load data\n",
    "\n",
    "#np.savez('Y_pred_my_clf.npz', Y_pred=Y_pred)\n",
    "data = np.load('Y_pred_my_clf.npz')\n",
    "#data['Y_pred']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.83      0.79      0.81       233\n",
      "          2       0.95      0.92      0.94       253\n",
      "          3       0.97      0.98      0.98       249\n",
      "          4       0.96      0.98      0.97       240\n",
      "          5       0.99      0.97      0.98       236\n",
      "          6       0.96      0.96      0.96       240\n",
      "          7       0.75      0.95      0.84       261\n",
      "          8       0.98      0.96      0.97       269\n",
      "          9       0.97      0.98      0.98       284\n",
      "         10       1.00      1.00      1.00       248\n",
      "         11       1.00      1.00      1.00       231\n",
      "         12       0.97      0.96      0.97       233\n",
      "         13       0.93      0.98      0.95       244\n",
      "         14       0.98      0.93      0.95       256\n",
      "         15       0.98      0.94      0.96       246\n",
      "         16       0.99      1.00      1.00       252\n",
      "         17       0.88      0.89      0.88       249\n",
      "         18       0.92      0.87      0.90       281\n",
      "         19       0.77      0.70      0.73       259\n",
      "         20       0.70      0.67      0.68       236\n",
      "\n",
      "avg / total       0.92      0.92      0.92      5000\n",
      "\n",
      "[[185   1   0   0   0   0   2   0   1   0   0   0   1   1   0   0   0   1\n",
      "    0  41]\n",
      " [  0 234   2   4   0   5   1   0   0   0   0   3   0   2   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0 245   0   0   3   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   2 235   2   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1 228   0   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "    3   0]\n",
      " [  0   4   3   0   0 230   1   0   0   0   0   0   1   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   5   0   0 248   5   0   0   0   0   1   1   0   0   0   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   1   9 258   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2   1 279   0   0   0   0   0   0   0   0   0\n",
      "    2   0]\n",
      " [  0   0   0   0   0   0   0   0   0 248   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 231   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   1   0   0   1   1   0   0   0   0 223   4   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   1   0   1   0   0   2   0   0   0   0   0 240   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   3   0   0   0   0   4   0   0   0   0   0   5 238   1   0   0   1\n",
      "    4   0]\n",
      " [  0   0   0   0   0   0   4   0   0   0   0   0   5   1 232   0   0   1\n",
      "    3   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 252   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   5   0   3   0   0   1   0   0   0   0 221   0\n",
      "   15   4]\n",
      " [  0   1   0   0   0   0  18   0   3   0   0   0   2   0   0   0   3 245\n",
      "    8   1]\n",
      " [  0   0   0   0   0   0  19   0   1   1   0   1   0   0   1   0  21  11\n",
      "  181  23]\n",
      " [ 37   0   0   0   0   0  11   0   0   0   0   0   0   1   0   2   6   5\n",
      "   16 158]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#If want to use Y_pred then replace data['Y_pred'] with Y_pred in these two below lines\n",
    "print(classification_report(Y_test,data['Y_pred']))\n",
    "print(confusion_matrix(Y_test,data['Y_pred']))\n",
    "\n",
    "data.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
